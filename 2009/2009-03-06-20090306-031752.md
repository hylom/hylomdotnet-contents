---
title: Botで/.Jにログインさせようとすると……
author: hylom
type: post
date: 2009-03-06T03:17:52+00:00
url: /2009/03/06/20090306-031752/
categories:
  - Slashdot

---
Pythonでスクレイピングしてみようと、下記のようなコードを書く。

> <div>
>   <p>
>     <tt> login_param = { <br /> &nbsp; "op":"userlogin"&#44; </br> <br /> &nbsp; "unickname":""&#44; </br> <br /> &nbsp; "returnto":"http://slashdot.jp"&#44; </br> <br /> &nbsp; "upasswd":""&#44; </br> <br /> #&nbsp; "login_temp":0&#44; </br> <br /> &nbsp; "userlogin":"ログイン"&#44; </br> <br /> } </br> <br /> &nbsp; </br> <br /> login_param["unickname"] = loginname </br> <br /> login_param["upasswd"] = passwd </br> <br /> &nbsp; </br> <br /> encoded_data = urllib.urlencode( login_param ) </br> <br /> &nbsp; </br> <br /> obj = urllib.urlopen(OTP_LOGIN_URL&#44; encoded_data ) </br> <br /> print obj.info() </br> </tt>
>   </p></p>
> </div>

で、これでログインさせようとすると、下記のようなヘッダが返ってくる。

> <div>
>   <p>
>     <tt> Date: Fri&#44; 06 Mar 2009 03:00:13 GMT <br /> Server: Apache/1.3.34 (Debian) mod_gzip/1.3.26.1a mod_perl/1.29 </br> <br /> SLASH_LOG_DATA: shtml </br> <br /> X-Powered-By: Slash 2.005001233 </br> <br /> X-Bender: Senseless death! The folk singer's best friend! </br> <br /> Vary: Accept-Encoding </br> <br /> Connection: close </br> <br /> Content-Type: text/html; charset=utf-8 </br> </tt>
>   </p></p>
> </div>

「X-Bender:」の内容は毎回ランダムに変わる。Cookieが返って来ていないのでもちろんログイン失敗なのだが、どうもボットかどうかをこちらが送るヘッダで判断しているようだ。ということで、今度は下記のようなコードでやってみたら成功。

> <div>
>   <p>
>     <tt> login_host = "slashdot.jp" <br /> login_path = "/login.pl" </br> <br /> &nbsp; </br> <br /> login_param = { </br> <br /> &nbsp; "op":"userlogin"&#44; </br> <br /> &nbsp; "unickname":""&#44; </br> <br /> &nbsp; "returnto":"http://slashdot.jp"&#44; </br> <br /> &nbsp; "upasswd":""&#44; </br> <br /> #&nbsp; "login_temp":0&#44; </br> <br /> &nbsp; "userlogin":"ログイン"&#44; </br> <br /> } </br> <br /> &nbsp; </br> <br /> login_param["unickname"] = loginname </br> <br /> login_param["upasswd"] = passwd </br> <br /> encoded_data = urllib.urlencode( login_param ) </br> <br /> &nbsp; </br> <br /> headers = { </br> <br /> &nbsp; "User-Agent": "Mozilla/5.0 (Windows; U; Windows NT 6.0; ja; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7 (.NET CLR 3.5.30729) " </br> <br /> &nbsp; "Content-type": "application/x-www-form-urlencoded"&#44; </br> <br /> &nbsp; "Accept": "text/plain"&#44; </br> <br /> } </br> <br /> &nbsp; </br> <br /> obj = httplib.HTTPConnection( login_host ) </br> <br /> obj.request( "POST"&#44; login_path&#44; encoded_data&#44; headers ) </br> <br /> resp = obj.getresponse() </br> <br /> headers = resp.getheaders() </br> <br /> &nbsp; </br> <br /> for item in headers: </br> <br /> &nbsp; &nbsp; print item </br> </tt>
>   </p></p>
> </div>

しかしやっぱり変なヘッダは返ってきていたり（笑）。

> <div>
>   <p>
>     <tt> x-leela：I'm a millionaire! Suddenly I have an opinion about the capital gains tax. </tt>
>   </p></p>
> </div>

Pythonは標準でWWWアクセスを行うモジュールが付属しているのはとても良いのだが、いまいちどれを使うべきかで混乱するな。urllib2を使えばヘッダを自由にいじれるようだけど、それならhttplibでごそごそやったほうが直感的ではある。

  [Permalink][1] |   [コメントを読む][2] |   [hylomの日記][3]

 [1]: http://slashdot.jp/~hylom/journal/469403
 [2]: http://slashdot.jp/~hylom/journal/469403#acomments
 [3]: http://slashdot.jp/~hylom/journal/